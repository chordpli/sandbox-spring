# 당신의 데이터 파이프라인은 안녕하십니까? 멱등성 전략 성능 심층 분석

**부제: Spring Boot와 PostgreSQL 환경에서 100배 성능 차이를 만든 결정적 요인**

새벽에 실행된 배치 작업이 아직도 끝나지 않았습니다. 간헐적으로 데이터가 중복 삽입되는 버그가 발생하고, 원인을 찾기 위해 수많은 로그를 뒤지고 있습니다. 데이터 기반 시스템을 운영하다 보면 누구나 한 번쯤 겪어봤을 법한 이 문제들의 중심에는 '멱등성(Idempotency)'이 있습니다.

멱등성이란 동일한 연산을 여러 번 수행하더라도 결과가 달라지지 않는 성질을 의미합니다. 데이터 파이프라인에서는 중복 데이터 적재를 방지하고 시스템의 안정성을 보장하는 핵심적인 개념이죠. 하지만 이 멱등성을 어떻게 구현하느냐에 따라, 시스템의 성능은 천국과 지옥을 오갈 수 있습니다. 

이 글에서는 실제 성능 테스트를 통해, 비효율적인 멱등성 전략이 어떻게 시스템을 마비시키는지, 그리고 현명한 전략이 어떻게 100배 이상의 성능 향상을 가져오는지 구체적인 코드와 데이터를 통해 증명해 보이고자 합니다.

## 1. 성능 테스트 설계: 현실적인 시나리오

정확한 비교를 위해 실제 운영 환경에서 마주할 법한 시나리오를 설정했습니다.

- **시스템 환경:** Spring Boot, JPA, PostgreSQL
- **데이터 모델:** `bank_transaction` (은행 거래 내역). 별도의 고유 ID 없이, `거래 시간`, `계좌번호`, `거래 유형`, `금액` 네 가지의 조합이 비즈니스 상의 고유 키 역할을 합니다.
- **테스트 상황:**
    1.  `bank_transaction` 테이블에 이미 **10만 건**의 데이터가 존재합니다.
    2.  이 상태에서 **10만 건의 신규 데이터**를 CSV 파일로부터 읽어와 적재합니다.
    3.  신규 데이터 10만 건 중 **90% (9만 건)는 기존 데이터와 중복**되며, 10% (1만 건)만이 순수한 신규 데이터입니다.

**목표:** 10만 건의 데이터를 적재하되, 중복은 걸러내고 신규 1만 건만 정확하게 삽입하는 데 걸리는 시간을 측정하고 비교합니다.

## 2. 대결: 4가지 멱등성 보장 전략

크게 '애플리케이션'에서 처리하는 방식과 '데이터베이스'에 위임하는 방식으로 나누어 네 가지 전략을 테스트했습니다.

### 전략 1: 애플리케이션 레벨에서 건별 확인 (최악의 접근법)

가장 직관적이지만 가장 비효율적인 방식입니다. 애플리케이션이 데이터 한 건마다 DB에 존재 여부를 묻고, 그 결과에 따라 삽입을 결정합니다.

```java
// IdempotentTest.java의 runScenario1Logic() 中

// ...
List<BankTransaction> testData = readCsv("idempotent/dataset_b.csv");

for (BankTransaction transaction : testData) {
    // 매 건마다 SELECT 쿼리 발생
    if (!idempotentService.exists(transaction)) {
        // 존재하지 않을 경우에만 INSERT 쿼리 발생
        idempotentService.saveAll(List.of(transaction));
    }
}
```

- **1-1:** 비즈니스 키 컬럼에 **인덱스가 없는** 상태로 실행
- **1-2:** 비즈니스 키 컬럼에 **복합 인덱스를 생성**한 상태로 실행

### 전략 2: 데이터베이스 레벨에서 일괄 처리 (현명한 접근법)

데이터 처리는 데이터가 가장 잘 아는 DB에 맡기는 방식입니다. 애플리케이션은 데이터를 모아 한 번에 DB로 보내고, DB가 내부적으로 중복 처리를 하도록 위임합니다.

```java
// IdempotentTest.java의 testScenario2_1() 中

// ...
List<BankTransaction> testData = readCsv("idempotent/dataset_b.csv");

String sql = "INSERT INTO ... ON CONFLICT (...) DO NOTHING";

// 데이터를 모아 단 한 번의 DB Call로 처리 위임
idempotentService.saveAllWithConflictResolution(testData, sql);
```

- **2-1: `ON CONFLICT` (복합 유니크 키):** PostgreSQL의 `INSERT ... ON CONFLICT` 구문을 활용합니다. 비즈니스 키 컬럼들에 복합 유니크 제약조건을 걸고, 중복 충돌 발생 시 `DO NOTHING` (아무것도 하지 않음) 옵션으로 처리합니다.
- **3-1: `ON CONFLICT` (해시 인덱스):** 복잡한 복합 키를 SHA-256 해시 함수를 통해 단일 `hash_value` 컬럼으로 변환하고, 이 컬럼에 유니크 인덱스를 생성하여 중복 검사를 수행합니다.
- **4-1: `Staging Table` + `MERGE`:** 모든 신규 데이터를 제약 조건이 없는 임시 테이블(Staging Table)에 먼저 빠르게 Bulk Insert 한 후, 단 한 번의 `MERGE` (또는 `INSERT ... ON CONFLICT`) 쿼리로 실제 테이블에 병합합니다.

## 3. 최종 결과: 52분 vs 2.3초

| 시나리오                                | 평균 실행 시간 (ms)     | 초당 처리량 (RPS) | 상태     |
| --------------------------------------- | ----------------------- | ----------------- | -------- |
| **1-1:** App-level (인덱스 없음)        | **3,126,000 (52분)**    | ~32               | **완료** |
| **1-2:** App-level (인덱스 있음)        | **98,748 (약 1분 38초)**| ~1,012            | **완료** |
| **2-1:** `ON CONFLICT` (복합 키)        | **2,322 (약 2.3초)**    | **~43,066**       | **완료** |
| **3-1:** `ON CONFLICT` (해시 인덱스)    | **3,349 (약 3.3초)**    | ~29,860           | **완료** |
| **4-1:** `Staging Table` + `MERGE`      | **3,011 (약 3.0초)**    | ~33,211           | **완료** |

*참고: 시나리오 1-1은 이전 테스트 결과를 사용했으며, 나머지는 RPS 계산 로직 수정 후 재실행한 결과입니다.*

## 4. 심층 분석: 무엇이 성능을 결정했는가?

### 왜 애플리케이션 레벨 처리는 실패했는가?

- **네트워크 오버헤드:** 전략 1-2는 10만 건의 데이터를 처리하기 위해 최소 10만 번의 `SELECT` 네트워크 왕복을 유발했습니다. 이 통신 비용이 쌓여 1분 38초라는 시간을 만들었습니다.
- **풀 테이블 스캔:** 인덱스가 없는 전략 1-1은 최악이었습니다. 매 `SELECT`마다 DB는 테이블 전체(10만 건 이상)를 샅샅이 뒤지는 '풀 테이블 스캔'을 10만 번 반복했습니다. 이는 `O(N*M)`의 끔찍한 복잡도를 가지며, 52분이라는 결과를 낳았습니다.
- **컨텍스트 스위칭 비용:** 애플리케이션과 데이터베이스는 독립된 프로세스입니다. 둘 사이의 잦은 호출은 비싼 컨텍스트 스위칭 비용을 발생시켜 전체적인 처리량을 저하시킵니다.

### 왜 데이터베이스 레벨 처리는 성공했는가?

- **집합 기반 처리(Set-based Processing):** DB 레벨 전략들은 데이터를 '한 건씩(Row-by-row)' 처리하는 대신, '하나의 집합(Set)'으로 간주하고 처리합니다. 이는 관계형 데이터베이스가 가장 잘하는 일입니다.
- **최소화된 네트워크:** 애플리케이션은 데이터를 거대한 묶음으로 만들어 단 한 번만 DB에 보냅니다. 10만 번의 왕복이 단 한 번으로 줄어드니 네트워크 오버헤드가 거의 사라집니다.
- **최적화된 실행 계획:** DB는 전체 데이터 집합과 목표(중복 제거 후 삽입)를 한 번에 인지하고, 가장 효율적인 단일 실행 계획을 수립하여 내부적으로 처리합니다. 모든 과정이 DB 엔진 내에서 최적화되어 실행되므로 비교할 수 없는 속도를 보여줍니다.

## 5. 최종 가이드: 당신의 상황에 맞는 최적의 전략

| 전략                      | 장점                                                              | 단점                                           | 추천 사용 사례                                                              |
| ------------------------- | ----------------------------------------------------------------- | ---------------------------------------------- | --------------------------------------------------------------------------- |
| **`ON CONFLICT` (복합/해시)** | **최고의 성능**, 간결한 구현.                                     | 단순 중복 무시 외 복잡한 로직 적용이 어려움.   | 데이터 구조가 단순하고, 중복 시 데이터를 무시해도 되는 대부분의 경우.         |
| **`Staging Table` + `MERGE`** | **최고 수준의 성능**, **높은 유연성** (업데이트, 로깅 등 로직 추가 가능). | `ON CONFLICT`에 비해 구현이 다소 복잡함.       | 대규모 ETL 파이프라인, 적재 시 데이터 변환/검증/업데이트 등 복잡한 규칙이 필요할 때. |

## 결론: 데이터 처리는 데이터가 있는 곳에서

이번 성능 테스트는 "데이터와 관련된 처리는 데이터가 저장된 곳, 즉 데이터베이스에서 수행하는 것이 가장 효율적이다"라는 기본 원칙을 다시 한번 증명했습니다.

만약 지금 운영하는 시스템의 배치 작업이 느리거나 데이터 적재 과정에서 문제를 겪고 있다면, 애플리케이션의 반복문 안에서 `SELECT`와 `INSERT`를 실행하고 있지는 않은지 점검해 보시길 바랍니다. 데이터베이스의 강력한 기능을 믿고 활용하는 것만으로도, 당신의 데이터 파이프라인은 훨씬 더 안정적이고 빨라질 수 있습니다.
